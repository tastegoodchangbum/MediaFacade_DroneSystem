from flask import Flask, render_template, Response, request
import threading
import cv2
from drone_opencv import window
import cv2
import win32gui

# run_AI_STT.py >> Libraries

import speech_recognition as sr
# google translator ì‚¬ìš©ìí™” ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
from my_lib import translate_lib
# kakao karlo model _ image generator ì‚¬ìš©ìí™” ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
from my_lib import image_generator_lib
# API_key load
import os
from dotenv import load_dotenv

# ìº¡ì³í•  ìœˆë„ìš° ì°½ ì´ë¦„ ì„¤ì •í•˜ê¸°

window_capture = "Mirroid"

load_dotenv()

kakao_api_key =  os.environ.get('kakao_api_key')

app = Flask(__name__)

output_frame = None
lock = threading.Lock()

def shutdown_server():
    func = request.environ.get('werkzeug.server.shutdown')
    if func is None:
        raise RuntimeError('Not running with the Werkzeug Server')
    func()

def capture_frames():
    global output_frame
    ESC_KEY = 27
    FRAME_RATE = 120
    SLEEP_TIME = 1 / FRAME_RATE

    capture = window.WindowCapture(window_capture, FRAME_RATE)

    while True:
        _, frame = capture.screenshot()
        with lock:
            output_frame = frame.copy()

def generate_frames():
    global output_frame
    while True:
        with lock:
            if output_frame is None:
                continue

            flag, encoded_image = cv2.imencode('.jpg', output_frame)
            if not flag:
                continue

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + bytearray(encoded_image) + b'\r\n')

@app.route('/')
def index():
    # return render_template('index.html')
    return print('hello!!')

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/shutdown', methods=['POST'])
def shutdown():
    shutdown_server()
    return 'Server shutting down...'

@app.route('/AI_gen_image', methods=['POST'])
def generator_image():
    # Googleì˜ STT ê¸°ëŠ¥ì„ êµ¬í˜„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    r = sr.Recognizer()
    with sr.Microphone() as source:
        # print(" ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€")
        # print("")
        print("ê±´ë¬¼ì— ê·¸ë¦¬ê³ ì‹¶ì€ ì›í•˜ëŠ” ê·¸ë¦¼ì„ ë§í•´ì¤˜! : ")
        # print("")
        # print(" ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€")

        audio = r.listen(source)
        
    mySpeech = r.recognize_google(audio, language='ko', show_all=True)

    # javascript setinterval & clearinterval êµ¬í˜„
    # ìŒì„± ì…ë ¥ì‹œ ë™ì‘, ì´ë¯¸ì§€ ìƒì„±ì‹œ ë°˜ë³µë¬¸ ì œê±°

    status = None
    while(status == None):
        try :
            prompt = mySpeech['alternative'][0]['transcript']

            print(f'ìŒì„± ì¸ì‹ : {prompt}')

            # prompt_purpose = 'ì‹¤ì œ ì‚¬ì§„ì²˜ëŸ¼ ë¹„ìŠ·í•˜ê²Œ ' + prompt

            prompt_purpose = prompt

            # print(prompt)

            translated_prompt = translate_lib.en_to_kr(prompt_purpose)

            print(f'ìŒì„± ì¸ì‹ ë²ˆì—­ : {translated_prompt}')
                    
            AI_Image = image_generator_lib.image_generator_karlo(translated_prompt, kakao_api_key)

            AI_Image.save("yolov5/segment/generated_AI_Image/generated_img.png")

            status = True

            return f'ì—¬ëŸ¬ë¶„ì´ ì£¼ì‹  ëª…ë ¹ : {prompt}\n ê·¸ë¦¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
                
        except sr.UnknownValueError:
            print("Google ìŒì„± ì¸ì‹ì´ ì˜¤ë””ì˜¤ë¥¼ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except sr.RequestError as e:
            print("Google ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì—ì„œ ê²°ê³¼ë¥¼ ìš”ì²­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.; {0}".format(e))

    

if __name__ == '__main__':
    capture_thread = threading.Thread(target=capture_frames)
    capture_thread.start()
    app.run(host='0.0.0.0', port=5000)